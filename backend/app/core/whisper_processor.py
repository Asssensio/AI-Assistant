# –ø—É—Ç—å: backend/app/core/whisper_processor.py
"""
Whisper –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤.
"""

import asyncio
import logging
from pathlib import Path
from typing import Dict, Optional, Any
import json

try:
    import whisper
    import torch
except ImportError:
    whisper = None
    torch = None

from libs.config import get_whisper_config, get_dev_config


logger = logging.getLogger(__name__)


class WhisperProcessor:
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper."""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Whisper –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞."""
        self.config = get_whisper_config()
        self.dev_config = get_dev_config()
        self.model = None
        self.is_initialized = False
        
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Whisper –º–æ–¥–µ–ª–∏."""
        if self.is_initialized or self.dev_config["mock_whisper"]:
            return
            
        if whisper is None:
            logger.warning("‚ö†Ô∏è Whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –†–∞–±–æ—Ç–∞ –≤ –º–æ–∫-—Ä–µ–∂–∏–º–µ.")
            return
            
        try:
            logger.info(f"ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ Whisper –º–æ–¥–µ–ª–∏: {self.config['model']}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
            device = self.config["device"]
            if device == "cuda" and not torch.cuda.is_available():
                logger.warning("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
                device = "cpu"
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            self.model = whisper.load_model(
                self.config["model"], 
                device=device
            )
            
            self.is_initialized = True
            logger.info(f"‚úÖ Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {device}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Whisper: {e}")
            self.model = None
    
    async def transcribe_file(self, file_path: str) -> Optional[Dict[str, Any]]:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞."""
        if self.dev_config["mock_whisper"]:
            return await self._mock_transcribe(file_path)
        
        if not self.is_initialized:
            await self.initialize()
            
        if self.model is None:
            return await self._mock_transcribe(file_path)
        
        try:
            logger.info(f"üéØ –ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {Path(file_path).name}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            result = await asyncio.get_event_loop().run_in_executor(
                None, self._transcribe_sync, file_path
            )
            
            if result:
                logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(result.get('text', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
                
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ {file_path}: {e}")
            return None
    
    def _transcribe_sync(self, file_path: str) -> Dict[str, Any]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ñ–∞–π–ª–∞."""
        try:
            # –û–ø—Ü–∏–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            options = {
                "language": self.config.get("language", "ru"),
                "task": self.config.get("task", "transcribe"),
                "fp16": self.config.get("compute_type") == "float16",
                "verbose": False,
                "temperature": 0.0,  # –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                "compression_ratio_threshold": 2.4,  # –§–∏–ª—å—Ç—Ä –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
                "logprob_threshold": -1.0,  # –§–∏–ª—å—Ç—Ä –Ω–∏–∑–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                "no_speech_threshold": 0.6,  # –ü–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º timeout —á–µ—Ä–µ–∑ signal (—Ç–æ–ª—å–∫–æ –¥–ª—è Unix)
            import signal
            import platform
            
            timeout_seconds = self.config.get("timeout", 300)  # 5 –º–∏–Ω—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
            def timeout_handler(signum, frame):
                raise TimeoutError(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø—Ä–µ–≤—ã—Å–∏–ª–∞ {timeout_seconds} —Å–µ–∫—É–Ω–¥")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º timeout —Ç–æ–ª—å–∫–æ –Ω–∞ Unix —Å–∏—Å—Ç–µ–º–∞—Ö
            if platform.system() != "Windows" and timeout_seconds > 0:
                signal.signal(signal.SIGALRM, timeout_handler)
                signal.alarm(timeout_seconds)
            
            try:
                # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
                result = self.model.transcribe(file_path, **options)
            finally:
                if platform.system() != "Windows" and timeout_seconds > 0:
                    signal.alarm(0)  # –û—Ç–∫–ª—é—á–∞–µ–º timeout
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return {
                "text": result["text"].strip(),
                "segments": [
                    {
                        "start": segment["start"],
                        "end": segment["end"],
                        "text": segment["text"].strip()
                    }
                    for segment in result.get("segments", [])
                ],
                "language": result.get("language", "unknown"),
                "duration": result.get("segments", [{}])[-1].get("end", 0) if result.get("segments") else 0,
                "model": self.config["model"]
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            raise
    
    async def _mock_transcribe(self, file_path: str) -> Dict[str, Any]:
        """–ú–æ–∫-—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏."""
        await asyncio.sleep(1)  # –ò–º–∏—Ç–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
        filename = Path(file_path).name
        mock_text = f"[–ú–û–ö –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø] –ê—É–¥–∏–æ—Ñ–∞–π–ª {filename} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤ —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏."
        
        return {
            "text": mock_text,
            "segments": [
                {
                    "start": 0.0,
                    "end": 10.0,
                    "text": mock_text
                }
            ],
            "language": "ru",
            "duration": 10.0,
            "model": "mock"
        }
    
    async def transcribe_batch(self, file_paths: list) -> Dict[str, Optional[Dict[str, Any]]]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ñ–∞–π–ª–æ–≤."""
        results = {}
        
        for file_path in file_paths:
            try:
                result = await self.transcribe_file(file_path)
                results[file_path] = result
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ {file_path}: {e}")
                results[file_path] = None
        
        return results
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."""
        if not self.is_initialized or self.model is None:
            return {
                "model": self.config["model"],
                "loaded": False,
                "device": "unknown",
                "mock_mode": self.dev_config["mock_whisper"]
            }
        
        return {
            "model": self.config["model"],
            "loaded": True,
            "device": self.config["device"],
            "mock_mode": False,
            "language": self.config.get("language", "ru"),
            "task": self.config.get("task", "transcribe")
        }
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        if self.model is not None:
            del self.model
            self.model = None
            
        if torch is not None and torch.cuda.is_available():
            torch.cuda.empty_cache()
            
        self.is_initialized = False
        logger.info("üßπ Whisper –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ—á–∏—â–µ–Ω") 